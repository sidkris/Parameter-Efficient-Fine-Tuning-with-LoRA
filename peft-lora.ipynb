{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from peft import AutoPeftModelForSequenceClassification, LoraConfig, TaskType, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for sms_spam contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/sms_spam\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"sms_spam\", split = \"train\").train_test_split(test_size = 0.2, shuffle = True, seed = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5756844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (4459, 2), 'test': (1115, 2)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [\"train\", \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f0f9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sms': 'URGENT!! Your 4* Costa Del Sol Holiday or £5000 await collection. Call 09050090044 Now toClaim. SAE, TC s, POBox334, Stockport, SK38xh, Cost£1.50/pm, Max10mins\\n',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a150750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in splits:\n",
    "    \n",
    "    tokenized_data[split] = data[split].map(\n",
    "        lambda x : tokenizer(x[\"sms\"], truncation = True),\n",
    "        batched = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d52bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4459\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d5ca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels = 2,\n",
    "    id2label = {0 : \"Not Spam\", 1 : \"Spam\"},\n",
    "    label2id = {\"Not Spam\" : 0, \"Spam\" : 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f50c3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    \n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feaaa69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f1f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis = 1)\n",
    "    \n",
    "    return {\"ACCURACY\" : (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55a730d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "        \n",
    "            model = model,\n",
    "    \n",
    "            args = TrainingArguments(\n",
    "            \n",
    "                    output_dir = \"./data/spam_not_spam\",\n",
    "                    learning_rate = 2e-5,\n",
    "                    per_device_train_batch_size = 32,\n",
    "                    per_device_eval_batch_size = 32,\n",
    "                    num_train_epochs = 1,\n",
    "                    weight_decay = 0.01,\n",
    "                    evaluation_strategy = \"epoch\",\n",
    "                    save_strategy = \"epoch\",\n",
    "                    load_best_model_at_end = True),\n",
    "    \n",
    "            train_dataset = tokenized_data[\"train\"],\n",
    "            eval_dataset = tokenized_data[\"test\"],\n",
    "            tokenizer = tokenizer,\n",
    "            data_collator = DataCollatorWithPadding(tokenizer = tokenizer),\n",
    "            compute_metrics = compute_metrics\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d62db092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c079a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6125432252883911,\n",
       " 'eval_ACCURACY': 0.8708520179372198,\n",
       " 'eval_runtime': 3.1488,\n",
       " 'eval_samples_per_second': 354.108,\n",
       " 'eval_steps_per_second': 11.115}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "                task_type = TaskType.SEQ_CLS,\n",
    "                inference_mode = False,\n",
    "                r = 16,\n",
    "                target_modules = ['q', 'k', 'v', 'q_lin', 'k_lin', 'v_lin'],\n",
    "                lora_alpha = 32,\n",
    "                lora_dropout = 0.05\n",
    "                \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "894046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6d65e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,626,628 || all params: 67,989,508 || trainable%: 2.3924691439155583\n"
     ]
    }
   ],
   "source": [
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_trainer = Trainer(\n",
    "        \n",
    "            model = lora_model,\n",
    "    \n",
    "            args = TrainingArguments(\n",
    "            \n",
    "                    output_dir = \"./lora_model\",\n",
    "                    learning_rate = 2e-5,\n",
    "                    per_device_train_batch_size = 32,\n",
    "                    per_device_eval_batch_size = 32,\n",
    "                    num_train_epochs = 2,\n",
    "                    weight_decay = 0.01,\n",
    "                    evaluation_strategy = \"epoch\",\n",
    "                    save_strategy = \"epoch\",\n",
    "                    load_best_model_at_end = True),\n",
    "    \n",
    "            train_dataset = tokenized_data[\"train\"],\n",
    "            eval_dataset = tokenized_data[\"test\"],\n",
    "            tokenizer = tokenizer,\n",
    "            data_collator = DataCollatorWithPadding(tokenizer = tokenizer),\n",
    "            compute_metrics = compute_metrics\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 00:50, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.204528</td>\n",
       "      <td>0.870852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.114275</td>\n",
       "      <td>0.968610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./lora_model/checkpoint-140 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=280, training_loss=0.2507209777832031, metrics={'train_runtime': 50.4012, 'train_samples_per_second': 176.94, 'train_steps_per_second': 5.555, 'total_flos': 179898355937160.0, 'train_loss': 0.2507209777832031, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.11427542567253113,\n",
       " 'eval_ACCURACY': 0.968609865470852,\n",
       " 'eval_runtime': 2.4266,\n",
       " 'eval_samples_per_second': 459.495,\n",
       " 'eval_steps_per_second': 14.424,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08c225e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "best_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    \n",
    "                    \"lora_model\",\n",
    "                    num_labels = 2\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_ = tokenized_data[\"test\"].select(range(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc96905a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for i in tests_:\n",
    "    \n",
    "    inputs_ = tokenizer(i[\"sms\"], truncation=True, padding=True, return_tensors=\"pt\", max_length=128)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = best_model(**inputs_).logits\n",
    "        pred_ = logits.argmax().item()\n",
    "        preds.append(pred_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    {\"sms\": tests_[\"sms\"], \"actual_class\" : tests_[\"label\"], \"predicted_class\": preds}\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>actual_class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pls dont forget to study\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok. Me watching tv too.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Short But Cute: \"Be a good person, but dont tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lets use it next week, princess :)\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gud mrng dear have a nice day\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>My friend just got here and says he's upping h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sir Goodmorning, Once free call me.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yeah I am, so I'll leave maybe 7ish?\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>So what did the bank say about the money?\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Got hella gas money, want to go on a grand nat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMS SERVICES. for your inclusive text credits,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Good morning pookie pie! Lol hope I didn't wak...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Today's Offer! Claim ur £150 worth of discount...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nan sonathaya soladha. Why boss?\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wow so healthy. Old airport rd lor. Cant thk o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>There is a first time for everything :)\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>It's ok, at least armand's still around\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wat time liao, where still got.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>That would be great. We'll be at the Guild. Co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sorry de i went to shop.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I'm doing da intro covers energy trends n pros...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FreeMsg Hey U, i just got 1 of these video/pic...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Where are you ? What are you doing ? Are yuou ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>My life Means a lot to me, Not because I love ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>R U &amp;SAM P IN EACHOTHER. IF WE MEET WE CAN GO ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>U don't know how stubborn I am. I didn't even ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>You've won tkts to the EURO2004 CUP FINAL or £...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I've sent my wife your text. After we buy them...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Why are u up so early?\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What makes you most happy?\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I came hostel. I m going to sleep. Plz call me...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Just seeing your missed call my dear brother. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I liked the new mobile\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>What Today-sunday..sunday is holiday..so no wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>She's good. How are you. Where r u working now\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Nope. I just forgot. Will show next week\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>&lt;Forwarded from 21870000&gt;Hi - this is your Mai...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>The gas station is like a block away from my h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>New TEXTBUDDY Chat 2 horny guys in ur area 4 j...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hurt me... Tease me... Make me cry... But in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>That's a shame! Maybe cld meet for few hrs tom...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Free Msg: Ringtone!From: http://tms. widelive....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Pls she needs to dat slowly or she will vomit ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>It didnt work again oh. Ok goodnight then. I.l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Depends on where u going lor.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>either way works for me. I am  &amp;lt;#&amp;gt;  year...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>I want to sent  &amp;lt;#&amp;gt; mesages today. Thats...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>How come i din c ü... Yup i cut my hair...\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Okie\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Talk sexy!! Make new friends or fall in love i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sms  actual_class  \\\n",
       "0                          Pls dont forget to study\\n             0   \n",
       "1                           Ok. Me watching tv too.\\n             0   \n",
       "2   Short But Cute: \"Be a good person, but dont tr...             0   \n",
       "3                Lets use it next week, princess :)\\n             0   \n",
       "4                     Gud mrng dear have a nice day\\n             0   \n",
       "5   My friend just got here and says he's upping h...             0   \n",
       "6               Sir Goodmorning, Once free call me.\\n             0   \n",
       "7              Yeah I am, so I'll leave maybe 7ish?\\n             0   \n",
       "8         So what did the bank say about the money?\\n             0   \n",
       "9   Got hella gas money, want to go on a grand nat...             0   \n",
       "10  SMS SERVICES. for your inclusive text credits,...             1   \n",
       "11  Good morning pookie pie! Lol hope I didn't wak...             0   \n",
       "12  Today's Offer! Claim ur £150 worth of discount...             1   \n",
       "13                 Nan sonathaya soladha. Why boss?\\n             0   \n",
       "14  Wow so healthy. Old airport rd lor. Cant thk o...             0   \n",
       "15          There is a first time for everything :)\\n             0   \n",
       "16          It's ok, at least armand's still around\\n             0   \n",
       "17                  Wat time liao, where still got.\\n             0   \n",
       "18  That would be great. We'll be at the Guild. Co...             0   \n",
       "19                         Sorry de i went to shop.\\n             0   \n",
       "20  I'm doing da intro covers energy trends n pros...             0   \n",
       "21  FreeMsg Hey U, i just got 1 of these video/pic...             1   \n",
       "22  Where are you ? What are you doing ? Are yuou ...             0   \n",
       "23  My life Means a lot to me, Not because I love ...             0   \n",
       "24  R U &SAM P IN EACHOTHER. IF WE MEET WE CAN GO ...             0   \n",
       "25  U don't know how stubborn I am. I didn't even ...             0   \n",
       "26  You've won tkts to the EURO2004 CUP FINAL or £...             1   \n",
       "27  I've sent my wife your text. After we buy them...             0   \n",
       "28                           Why are u up so early?\\n             0   \n",
       "29                       What makes you most happy?\\n             0   \n",
       "30  I came hostel. I m going to sleep. Plz call me...             0   \n",
       "31  Just seeing your missed call my dear brother. ...             0   \n",
       "32                           I liked the new mobile\\n             0   \n",
       "33  What Today-sunday..sunday is holiday..so no wo...             0   \n",
       "34   She's good. How are you. Where r u working now\\n             0   \n",
       "35         Nope. I just forgot. Will show next week\\n             0   \n",
       "36  <Forwarded from 21870000>Hi - this is your Mai...             1   \n",
       "37  The gas station is like a block away from my h...             0   \n",
       "38  New TEXTBUDDY Chat 2 horny guys in ur area 4 j...             1   \n",
       "39  Hurt me... Tease me... Make me cry... But in t...             0   \n",
       "40  That's a shame! Maybe cld meet for few hrs tom...             0   \n",
       "41  Free Msg: Ringtone!From: http://tms. widelive....             1   \n",
       "42  Pls she needs to dat slowly or she will vomit ...             0   \n",
       "43  It didnt work again oh. Ok goodnight then. I.l...             0   \n",
       "44                    Depends on where u going lor.\\n             0   \n",
       "45  either way works for me. I am  &lt;#&gt;  year...             0   \n",
       "46  I want to sent  &lt;#&gt; mesages today. Thats...             0   \n",
       "47       How come i din c ü... Yup i cut my hair...\\n             0   \n",
       "48                                             Okie\\n             0   \n",
       "49  Talk sexy!! Make new friends or fall in love i...             1   \n",
       "\n",
       "    predicted_class  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "5                 0  \n",
       "6                 0  \n",
       "7                 0  \n",
       "8                 0  \n",
       "9                 0  \n",
       "10                1  \n",
       "11                0  \n",
       "12                1  \n",
       "13                0  \n",
       "14                0  \n",
       "15                0  \n",
       "16                0  \n",
       "17                0  \n",
       "18                0  \n",
       "19                0  \n",
       "20                0  \n",
       "21                0  \n",
       "22                0  \n",
       "23                0  \n",
       "24                0  \n",
       "25                0  \n",
       "26                1  \n",
       "27                0  \n",
       "28                0  \n",
       "29                0  \n",
       "30                0  \n",
       "31                0  \n",
       "32                0  \n",
       "33                0  \n",
       "34                0  \n",
       "35                0  \n",
       "36                1  \n",
       "37                0  \n",
       "38                1  \n",
       "39                0  \n",
       "40                0  \n",
       "41                1  \n",
       "42                0  \n",
       "43                0  \n",
       "44                0  \n",
       "45                0  \n",
       "46                0  \n",
       "47                0  \n",
       "48                0  \n",
       "49                0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3229b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9559c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed9d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba65a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
